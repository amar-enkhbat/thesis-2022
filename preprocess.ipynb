{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd012a080800f0f6eb796e5b7bb3766959f93357da22153b807b16296d7db7fdd01",
   "display_name": "Python 3.8.9  ('env': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "12a080800f0f6eb796e5b7bb3766959f93357da22153b807b16296d7db7fdd01"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "random_seed = 1\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For remapping original labels in to interpretable labels\n",
    "labels_remap = {\"R01\": {\"T0\": \"eyes_open\"},\n",
    "          \"R02\": {\"T0\": \"eyes_closed\"},\n",
    "          \"R03\": {\"T0\": \"rest\", \"T1\": \"real_left_fist\", \"T2\": \"real_right_fist\"},\n",
    "          \"R04\": {\"T0\": \"rest\", \"T1\": \"imagine_left_fist\", \"T2\": \"imagine_right_fist\"},\n",
    "          \"R05\": {\"T0\": \"rest\", \"T1\": \"real_both_fist\", \"T2\": \"real_both_feet\"},\n",
    "          \"R06\": {\"T0\": \"rest\", \"T1\": \"imagine_both_fist\", \"T2\": \"imagine_both_feet\"},\n",
    "          \"R07\": {\"T0\": \"rest\", \"T1\": \"real_left_fist\", \"T2\": \"real_right_fist\"},\n",
    "          \"R08\": {\"T0\": \"rest\", \"T1\": \"imagine_left_fist\", \"T2\": \"imagine_right_fist\"},\n",
    "          \"R09\": {\"T0\": \"rest\", \"T1\": \"real_both_fist\", \"T2\": \"real_both_feet\"},\n",
    "          \"R10\": {\"T0\": \"rest\", \"T1\": \"imagine_both_fist\", \"T2\": \"imagine_both_feet\"},\n",
    "          \"R11\": {\"T0\": \"rest\", \"T1\": \"real_left_fist\", \"T2\": \"real_right_fist\"},\n",
    "          \"R12\": {\"T0\": \"rest\", \"T1\": \"imagine_left_fist\", \"T2\": \"imagine_right_fist\"},\n",
    "          \"R13\": {\"T0\": \"rest\", \"T1\": \"real_both_fist\", \"T2\": \"real_both_feet\"},\n",
    "          \"R14\": {\"T0\": \"rest\", \"T1\": \"imagine_both_fist\", \"T2\": \"imagine_both_feet\"}\n",
    "         }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"dataset/physionet.org/files/eegmmidb/1.0.0/\"\n",
    "save_path = \"dataset/physionet.org_csv\"\n",
    "\n",
    "if not os.path.isdir(save_path):\n",
    "    os.mkdir(save_path)\n",
    "    \n",
    "subjects_idc = [f\"S{i:03d}\" for i in range(1, 110)]\n",
    "# Recorded in 160 times per second\n",
    "freq = 160\n",
    "timestep = pd.to_timedelta(f\"{1 / freq} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert length annoations into timestep annotations\n",
    "def process_annots(annot_df):\n",
    "    new_annots = {\"timestamp\": [], \"label\": []}\n",
    "    for onset, duration, description in annot_df.values:\n",
    "        duration = pd.to_timedelta(f\"{duration} seconds\")\n",
    "        stop_onset = onset + duration\n",
    "\n",
    "        while onset != stop_onset:\n",
    "            new_annots[\"timestamp\"].append(onset)\n",
    "            new_annots[\"label\"].append(description)\n",
    "            onset = onset + timestep\n",
    "\n",
    "    new_annots = pd.DataFrame(new_annots)\n",
    "    return new_annots\n",
    "\n",
    "# Change original labels into interpretable labels\n",
    "def change_labels(filename, label_df):\n",
    "    filename = filename.rstrip(\".edf\")[-3:]\n",
    "    label_df[\"description\"] = label_df[\"description\"].replace(labels_remap[filename])\n",
    "    return label_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 91%|█████████ | 99/109 [17:46<01:48, 10.81s/it]<ipython-input-5-bb64e370b234>:13: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(run_path, verbose=False)\n",
      "<ipython-input-5-bb64e370b234>:13: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(run_path, verbose=False)\n",
      "<ipython-input-5-bb64e370b234>:13: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(run_path, verbose=False)\n",
      "<ipython-input-5-bb64e370b234>:13: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(run_path, verbose=False)\n",
      "<ipython-input-5-bb64e370b234>:13: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(run_path, verbose=False)\n",
      "<ipython-input-5-bb64e370b234>:13: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(run_path, verbose=False)\n",
      "<ipython-input-5-bb64e370b234>:13: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(run_path, verbose=False)\n",
      "<ipython-input-5-bb64e370b234>:13: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(run_path, verbose=False)\n",
      "<ipython-input-5-bb64e370b234>:13: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(run_path, verbose=False)\n",
      "<ipython-input-5-bb64e370b234>:13: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(run_path, verbose=False)\n",
      "<ipython-input-5-bb64e370b234>:13: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(run_path, verbose=False)\n",
      "<ipython-input-5-bb64e370b234>:13: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw = mne.io.read_raw_edf(run_path, verbose=False)\n",
      "100%|██████████| 109/109 [19:35<00:00, 10.79s/it]\n"
     ]
    }
   ],
   "source": [
    "# For recording length differences between data_df and labels_df\n",
    "diff_df = []\n",
    "\n",
    "# Convert dataset into .csv and save\n",
    "for subject_id in tqdm(subjects_idc):\n",
    "    runs = os.listdir(os.path.join(dataset_path, subject_id))\n",
    "    runs = [i for i in runs if i.endswith(\".edf\")]\n",
    "    runs.sort()\n",
    "\n",
    "    for run in runs:\n",
    "        run_path = os.path.join(dataset_path, subject_id, run)\n",
    "\n",
    "        raw = mne.io.read_raw_edf(run_path, verbose=False)\n",
    "        raw_data = raw.to_data_frame()\n",
    "        raw_data = raw_data.drop(columns=[\"time\"])\n",
    "        original_data_length = raw_data.shape[0]\n",
    "\n",
    "        raw_labels = raw.annotations.to_data_frame()\n",
    "        raw_labels = change_labels(run, raw_labels)\n",
    "        raw_labels = process_annots(raw_labels)\n",
    "        \n",
    "\n",
    "        if raw_data.shape[0] != raw_labels.shape[0]:\n",
    "            len_diff = raw_data.shape[0] - raw_labels.shape[0]\n",
    "            \n",
    "            unique = raw_data.iloc[raw_labels.shape[0]:].values\n",
    "            unique = np.unique(unique)\n",
    "\n",
    "            diff_df.append({\"filename\": run, \"length_diff\": len_diff, \"diff_value_unique\": unique})\n",
    "        \n",
    "        raw_data = pd.concat([raw_labels, raw_data], axis=1)\n",
    "        raw_data = raw_data.dropna()\n",
    "\n",
    "        assert raw_data.shape[0] == raw_labels.shape[0] or raw_data.shape[0] == original_data_length\n",
    "\n",
    "        if not os.path.exists(os.path.join(save_path, subject_id)):\n",
    "            os.mkdir(os.path.join(save_path, subject_id))\n",
    "        raw_data.to_csv(os.path.join(save_path, subject_id, run.rstrip(\".edf\") + \".csv\"), index=False)\n",
    "        raw_labels.to_csv(os.path.join(save_path, subject_id, run.rstrip(\".edf\") + \"_labels.csv\"), index=False)\n",
    "\n",
    "diff_df = pd.DataFrame(diff_df)\n",
    "diff_df.to_csv(os.path.join(save_path, \"data_label_diff.csv\"))\n",
    "\n",
    "# Note 1: subject 100 showed errors. \n",
    "# we're ignoring subjects:\n",
    "# #88, 89, 92 100 anyway.\n",
    "\n",
    "# Note 2: when len(raw_data.shape[0]) != len(raw_labels.shape[0]) the leftover dataframe is [0.] or [], when diff is positive or negative respectively\n",
    "# #88, 92, 100 has more labels than data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 109/109 [18:17<00:00, 10.07s/it]\n"
     ]
    }
   ],
   "source": [
    "# Concat data of each subject\n",
    "\n",
    "# For getting columns names only\n",
    "temp = pd.read_csv(\"dataset/physionet.org_csv/S001/S001R01.csv\")\n",
    "\n",
    "# Save .csv files as one .csv per subject\n",
    "for subject_id in tqdm(subjects_idc):\n",
    "    runs = os.listdir(os.path.join(save_path, subject_id))\n",
    "    # print(runs)\n",
    "    runs = [i for i in runs if len(i) == 11]\n",
    "    runs.sort()\n",
    "    full_data = pd.DataFrame([], columns=temp.columns)\n",
    "    for run in runs:\n",
    "        run_path = os.path.join(save_path, subject_id, run)\n",
    "        data = pd.read_csv(run_path)\n",
    "        full_data = pd.concat([full_data, data], axis=0)\n",
    "    full_data = full_data.reset_index()\n",
    "    full_data = full_data.rename(columns = {'index':'original_index'})\n",
    "    full_data.to_csv(run_path[:-7] + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        original_index                   timestamp              label   Fc5.  \\\n",
       "0                    0  2009-08-12 16:15:00.000000          eyes_open  108.0   \n",
       "1                    1  2009-08-12 16:15:00.006250          eyes_open   98.0   \n",
       "2                    2  2009-08-12 16:15:00.012500          eyes_open   78.0   \n",
       "3                    3  2009-08-12 16:15:00.018750          eyes_open   72.0   \n",
       "4                    4  2009-08-12 16:15:00.025000          eyes_open   89.0   \n",
       "...                ...                         ...                ...    ...   \n",
       "255307           19675  2009-08-12 16:17:02.968750  imagine_both_feet   -3.0   \n",
       "255308           19676  2009-08-12 16:17:02.975000  imagine_both_feet   -2.0   \n",
       "255309           19677  2009-08-12 16:17:02.981250  imagine_both_feet   -2.0   \n",
       "255310           19678  2009-08-12 16:17:02.987500  imagine_both_feet    1.0   \n",
       "255311           19679  2009-08-12 16:17:02.993750  imagine_both_feet    2.0   \n",
       "\n",
       "         Fc3.   Fc1.  Fcz.  Fc2.   Fc4.  Fc6.  ...  P8..  Po7.  Po3.  Poz.  \\\n",
       "0       125.0  166.0  20.0  16.0   52.0  63.0  ...   4.0  27.0 -24.0  14.0   \n",
       "1       135.0  172.0  29.0  22.0  100.0  67.0  ...  -8.0  40.0 -17.0  12.0   \n",
       "2       138.0  140.0  30.0  21.0   80.0  76.0  ...  -7.0  55.0  -5.0  20.0   \n",
       "3       146.0  127.0  33.0  22.0   61.0  77.0  ...  -2.0  56.0  -2.0  23.0   \n",
       "4       145.0  130.0  38.0  26.0   -5.0  84.0  ...   0.0  51.0  -7.0  15.0   \n",
       "...       ...    ...   ...   ...    ...   ...  ...   ...   ...   ...   ...   \n",
       "255307   69.0   86.0  21.0  28.0    3.0 -53.0  ...  39.0  25.0  70.0  30.0   \n",
       "255308   50.0   88.0  17.0  23.0   -8.0 -59.0  ...  25.0  10.0  58.0  29.0   \n",
       "255309   32.0   72.0  10.0   9.0  -11.0 -67.0  ...  14.0  -3.0  46.0  25.0   \n",
       "255310   10.0   64.0  -6.0  -3.0  -13.0 -77.0  ...  24.0   4.0  58.0  42.0   \n",
       "255311    8.0   87.0  -1.0   5.0   15.0 -67.0  ...  33.0  13.0  69.0  60.0   \n",
       "\n",
       "        Po4.  Po8.  O1..   Oz..  O2..  Iz..  \n",
       "0       -4.0   2.0  13.0   94.0  26.0 -12.0  \n",
       "1       -7.0  -3.0  14.0   91.0  32.0 -14.0  \n",
       "2       -2.0   2.0  25.0   99.0  46.0  -2.0  \n",
       "3       -2.0  -1.0  22.0  100.0  40.0  -4.0  \n",
       "4      -13.0  -8.0  10.0   88.0  21.0 -13.0  \n",
       "...      ...   ...   ...    ...   ...   ...  \n",
       "255307  66.0  30.0  24.0   10.0  19.0  78.0  \n",
       "255308  59.0  17.0  11.0    5.0  12.0  63.0  \n",
       "255309  53.0  10.0   4.0    2.0   6.0  49.0  \n",
       "255310  67.0  25.0  16.0   14.0  23.0  53.0  \n",
       "255311  81.0  44.0  27.0   29.0  41.0  64.0  \n",
       "\n",
       "[255312 rows x 67 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>original_index</th>\n      <th>timestamp</th>\n      <th>label</th>\n      <th>Fc5.</th>\n      <th>Fc3.</th>\n      <th>Fc1.</th>\n      <th>Fcz.</th>\n      <th>Fc2.</th>\n      <th>Fc4.</th>\n      <th>Fc6.</th>\n      <th>...</th>\n      <th>P8..</th>\n      <th>Po7.</th>\n      <th>Po3.</th>\n      <th>Poz.</th>\n      <th>Po4.</th>\n      <th>Po8.</th>\n      <th>O1..</th>\n      <th>Oz..</th>\n      <th>O2..</th>\n      <th>Iz..</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2009-08-12 16:15:00.000000</td>\n      <td>eyes_open</td>\n      <td>108.0</td>\n      <td>125.0</td>\n      <td>166.0</td>\n      <td>20.0</td>\n      <td>16.0</td>\n      <td>52.0</td>\n      <td>63.0</td>\n      <td>...</td>\n      <td>4.0</td>\n      <td>27.0</td>\n      <td>-24.0</td>\n      <td>14.0</td>\n      <td>-4.0</td>\n      <td>2.0</td>\n      <td>13.0</td>\n      <td>94.0</td>\n      <td>26.0</td>\n      <td>-12.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2009-08-12 16:15:00.006250</td>\n      <td>eyes_open</td>\n      <td>98.0</td>\n      <td>135.0</td>\n      <td>172.0</td>\n      <td>29.0</td>\n      <td>22.0</td>\n      <td>100.0</td>\n      <td>67.0</td>\n      <td>...</td>\n      <td>-8.0</td>\n      <td>40.0</td>\n      <td>-17.0</td>\n      <td>12.0</td>\n      <td>-7.0</td>\n      <td>-3.0</td>\n      <td>14.0</td>\n      <td>91.0</td>\n      <td>32.0</td>\n      <td>-14.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2009-08-12 16:15:00.012500</td>\n      <td>eyes_open</td>\n      <td>78.0</td>\n      <td>138.0</td>\n      <td>140.0</td>\n      <td>30.0</td>\n      <td>21.0</td>\n      <td>80.0</td>\n      <td>76.0</td>\n      <td>...</td>\n      <td>-7.0</td>\n      <td>55.0</td>\n      <td>-5.0</td>\n      <td>20.0</td>\n      <td>-2.0</td>\n      <td>2.0</td>\n      <td>25.0</td>\n      <td>99.0</td>\n      <td>46.0</td>\n      <td>-2.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2009-08-12 16:15:00.018750</td>\n      <td>eyes_open</td>\n      <td>72.0</td>\n      <td>146.0</td>\n      <td>127.0</td>\n      <td>33.0</td>\n      <td>22.0</td>\n      <td>61.0</td>\n      <td>77.0</td>\n      <td>...</td>\n      <td>-2.0</td>\n      <td>56.0</td>\n      <td>-2.0</td>\n      <td>23.0</td>\n      <td>-2.0</td>\n      <td>-1.0</td>\n      <td>22.0</td>\n      <td>100.0</td>\n      <td>40.0</td>\n      <td>-4.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2009-08-12 16:15:00.025000</td>\n      <td>eyes_open</td>\n      <td>89.0</td>\n      <td>145.0</td>\n      <td>130.0</td>\n      <td>38.0</td>\n      <td>26.0</td>\n      <td>-5.0</td>\n      <td>84.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>51.0</td>\n      <td>-7.0</td>\n      <td>15.0</td>\n      <td>-13.0</td>\n      <td>-8.0</td>\n      <td>10.0</td>\n      <td>88.0</td>\n      <td>21.0</td>\n      <td>-13.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>255307</th>\n      <td>19675</td>\n      <td>2009-08-12 16:17:02.968750</td>\n      <td>imagine_both_feet</td>\n      <td>-3.0</td>\n      <td>69.0</td>\n      <td>86.0</td>\n      <td>21.0</td>\n      <td>28.0</td>\n      <td>3.0</td>\n      <td>-53.0</td>\n      <td>...</td>\n      <td>39.0</td>\n      <td>25.0</td>\n      <td>70.0</td>\n      <td>30.0</td>\n      <td>66.0</td>\n      <td>30.0</td>\n      <td>24.0</td>\n      <td>10.0</td>\n      <td>19.0</td>\n      <td>78.0</td>\n    </tr>\n    <tr>\n      <th>255308</th>\n      <td>19676</td>\n      <td>2009-08-12 16:17:02.975000</td>\n      <td>imagine_both_feet</td>\n      <td>-2.0</td>\n      <td>50.0</td>\n      <td>88.0</td>\n      <td>17.0</td>\n      <td>23.0</td>\n      <td>-8.0</td>\n      <td>-59.0</td>\n      <td>...</td>\n      <td>25.0</td>\n      <td>10.0</td>\n      <td>58.0</td>\n      <td>29.0</td>\n      <td>59.0</td>\n      <td>17.0</td>\n      <td>11.0</td>\n      <td>5.0</td>\n      <td>12.0</td>\n      <td>63.0</td>\n    </tr>\n    <tr>\n      <th>255309</th>\n      <td>19677</td>\n      <td>2009-08-12 16:17:02.981250</td>\n      <td>imagine_both_feet</td>\n      <td>-2.0</td>\n      <td>32.0</td>\n      <td>72.0</td>\n      <td>10.0</td>\n      <td>9.0</td>\n      <td>-11.0</td>\n      <td>-67.0</td>\n      <td>...</td>\n      <td>14.0</td>\n      <td>-3.0</td>\n      <td>46.0</td>\n      <td>25.0</td>\n      <td>53.0</td>\n      <td>10.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>6.0</td>\n      <td>49.0</td>\n    </tr>\n    <tr>\n      <th>255310</th>\n      <td>19678</td>\n      <td>2009-08-12 16:17:02.987500</td>\n      <td>imagine_both_feet</td>\n      <td>1.0</td>\n      <td>10.0</td>\n      <td>64.0</td>\n      <td>-6.0</td>\n      <td>-3.0</td>\n      <td>-13.0</td>\n      <td>-77.0</td>\n      <td>...</td>\n      <td>24.0</td>\n      <td>4.0</td>\n      <td>58.0</td>\n      <td>42.0</td>\n      <td>67.0</td>\n      <td>25.0</td>\n      <td>16.0</td>\n      <td>14.0</td>\n      <td>23.0</td>\n      <td>53.0</td>\n    </tr>\n    <tr>\n      <th>255311</th>\n      <td>19679</td>\n      <td>2009-08-12 16:17:02.993750</td>\n      <td>imagine_both_feet</td>\n      <td>2.0</td>\n      <td>8.0</td>\n      <td>87.0</td>\n      <td>-1.0</td>\n      <td>5.0</td>\n      <td>15.0</td>\n      <td>-67.0</td>\n      <td>...</td>\n      <td>33.0</td>\n      <td>13.0</td>\n      <td>69.0</td>\n      <td>60.0</td>\n      <td>81.0</td>\n      <td>44.0</td>\n      <td>27.0</td>\n      <td>29.0</td>\n      <td>41.0</td>\n      <td>64.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>255312 rows × 67 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "full_data"
   ]
  },
  {
   "source": [
    "# Create training data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclusions = [\"S088\", \"S089\", \"S092\", \"S100\"]\n",
    "subjects_idc = [f\"S{i:03d}\" for i in range(1, 110)]\n",
    "subjects_idc = [i for i in subjects_idc if i not in exclusions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idc = random.sample(subjects_idc, 10)\n",
    "train_idc = [i for i in subjects_idc if i not in test_idc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['S001', 'S002', 'S003', 'S004', 'S005', 'S006', 'S007', 'S008', 'S010', 'S011', 'S012', 'S013', 'S014', 'S015', 'S017', 'S019', 'S020', 'S021', 'S022', 'S023', 'S024', 'S025', 'S026', 'S027', 'S028', 'S029', 'S030', 'S031', 'S032', 'S034', 'S035', 'S036', 'S037', 'S038', 'S039', 'S040', 'S041', 'S042', 'S043', 'S044', 'S045', 'S046', 'S047', 'S048', 'S049', 'S050', 'S051', 'S052', 'S053', 'S054', 'S055', 'S056', 'S057', 'S059', 'S060', 'S062', 'S063', 'S065', 'S066', 'S067', 'S068', 'S069', 'S070', 'S071', 'S072', 'S074', 'S075', 'S076', 'S077', 'S078', 'S079', 'S080', 'S081', 'S082', 'S083', 'S084', 'S085', 'S086', 'S087', 'S090', 'S091', 'S093', 'S094', 'S095', 'S096', 'S097', 'S098', 'S099', 'S101', 'S103', 'S104', 'S105', 'S106', 'S108', 'S109']\n95\n"
     ]
    }
   ],
   "source": [
    "print(train_idc)\n",
    "print(len(train_idc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['S018', 'S073', 'S107', 'S102', 'S009', 'S033', 'S016', 'S064', 'S058', 'S061']\n"
     ]
    }
   ],
   "source": [
    "print(test_idc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"cross_subject_data_1.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = np.empty((0, 64))\n",
    "# y_train = np.empty((0,))\n",
    "# X_test = np.empty((0, 64))\n",
    "# y_test = np.empty((0,))\n",
    "\n",
    "# for subject_id in tqdm(train_idc):\n",
    "#     df = pd.read_csv(f\"dataset/physionet.org_csv/{subject_id}/{subject_id}.csv\")\n",
    "#     X_train = np.vstack((X_train, df.iloc[:, 3:].values))\n",
    "#     y_train = np.hstack((y_train, df[\"label\"].values))\n",
    "\n",
    "# for subject_id in tqdm(test_idc):\n",
    "#     df = pd.read_csv(f\"dataset/physionet.org_csv/{subject_id}/{subject_id}.csv\")\n",
    "#     X_test = np.vstack((X_test, df.iloc[:, 3:].values))\n",
    "#     y_test = np.hstack((y_test, df[\"label\"].values))\n",
    "\n",
    "# cross_subject_data = {\"train_x\": X_train, \"train_y\": y_train, \"test_x\": X_test, \"test_y\": y_test}"
   ]
  }
 ]
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, Dataset\n",
    "\n",
    "import numpy as np \n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "random_seed = 1\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('runs/fcn')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "X = pickle.load(open('../dataset/train/cross_subject_data_5_subjects.pickle', 'rb'))\n",
    "y = X['train_y']\n",
    "\n",
    "X = X['train_x'].astype(np.float32)\n",
    "\n",
    "label_map = {'imagine_both_feet': 0, 'imagine_both_fist': 1, 'imagine_left_fist': 2, 'imagine_right_fist': 3}\n",
    "y = np.vectorize(label_map.__getitem__)(y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Convert data to [n_samples, n_channels] -> [n_samples, seq_len, n_channels]"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "seq_len = 100\n",
    "n_channels = 64\n",
    "\n",
    "def reshape_data(X, y, seq_len):\n",
    "    print('X original shape:', X.shape)\n",
    "    print('y original shape:', y.shape)\n",
    "    len_tail = X.shape[0] % seq_len\n",
    "    X = X[:-len_tail].reshape(-1, seq_len, n_channels)\n",
    "    y = y[:-len_tail].reshape(-1, seq_len)\n",
    "\n",
    "    print('X conversion shape:', X.shape)\n",
    "    print('y conversion shape:', y.shape)\n",
    "    return X, y[:, -1]\n",
    "\n",
    "X, y = reshape_data(X, y, seq_len)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X original shape: (295008, 64)\n",
      "y original shape: (295008,)\n",
      "X conversion shape: (2950, 100, 64)\n",
      "y conversion shape: (2950, 100)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed, stratify=y)\n",
    "def print_class_dist(y):\n",
    "    dist = {}\n",
    "\n",
    "    labels = np.unique(y)\n",
    "    for label in labels:\n",
    "        dist[str(label)] = len(y[y == label]) / len(y)\n",
    "    print(dist)\n",
    "print_class_dist(y)\n",
    "print_class_dist(y_train)\n",
    "print_class_dist(y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'0': 0.24745762711864408, '1': 0.25254237288135595, '2': 0.25864406779661014, '3': 0.24135593220338983}\n",
      "{'0': 0.24745762711864408, '1': 0.25254237288135595, '2': 0.2584745762711864, '3': 0.24152542372881355}\n",
      "{'0': 0.24745762711864408, '1': 0.25254237288135595, '2': 0.2593220338983051, '3': 0.24067796610169492}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Normalize\n",
    "mean, std = X.mean(), X.std()\n",
    "X_train = (X_train - mean) / std\n",
    "X_test = (X_test - mean) / std"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "X_train - 10"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[ -9.819402 ,  -9.806805 ,  -9.819402 , ...,  -9.580066 ,\n",
       "          -9.617856 ,  -9.643049 ],\n",
       "        [ -9.504486 ,  -9.605259 ,  -9.617856 , ...,  -9.5548725,\n",
       "          -9.605259 ,  -9.630452 ],\n",
       "        [ -9.428906 ,  -9.643049 ,  -9.655645 , ...,  -9.529679 ,\n",
       "          -9.655645 ,  -9.592663 ],\n",
       "        ...,\n",
       "        [ -9.781611 ,  -9.706032 ,  -9.718629 , ...,  -9.731225 ,\n",
       "          -9.680839 ,  -9.857191 ],\n",
       "        [ -9.806805 ,  -9.794209 ,  -9.794209 , ...,  -9.655645 ,\n",
       "          -9.617856 ,  -9.743822 ],\n",
       "        [ -9.819402 ,  -9.668242 ,  -9.668242 , ...,  -9.643049 ,\n",
       "          -9.56747  ,  -9.718629 ]],\n",
       "\n",
       "       [[-10.222493 , -10.134316 , -10.134316 , ..., -10.373652 ,\n",
       "         -10.550005 , -10.386249 ],\n",
       "        [-10.348459 , -10.2602825, -10.222493 , ..., -10.348459 ,\n",
       "         -10.512215 , -10.348459 ],\n",
       "        [-10.487021 , -10.348459 , -10.27288  , ..., -10.209896 ,\n",
       "         -10.398846 , -10.209896 ],\n",
       "        ...,\n",
       "        [ -9.731225 ,  -9.41631  ,  -9.5548725, ...,  -9.831998 ,\n",
       "          -9.869788 ,  -9.970561 ],\n",
       "        [ -9.655645 ,  -9.365924 ,  -9.49189  , ...,  -9.882384 ,\n",
       "          -9.882384 , -10.00835  ],\n",
       "        [ -9.668242 ,  -9.403713 ,  -9.49189  , ...,  -9.794209 ,\n",
       "          -9.806805 ,  -9.882384 ]],\n",
       "\n",
       "       [[ -9.9075775,  -9.781611 ,  -9.781611 , ...,  -9.806805 ,\n",
       "          -9.806805 ,  -9.894981 ],\n",
       "        [-10.1973   ,  -9.945368 ,  -9.945368 , ...,  -9.894981 ,\n",
       "          -9.894981 ,  -9.932771 ],\n",
       "        [-10.096527 ,  -9.957964 ,  -9.957964 , ...,  -9.706032 ,\n",
       "          -9.706032 ,  -9.756418 ],\n",
       "        ...,\n",
       "        [-10.235089 ,  -9.920175 ,  -9.920175 , ...,  -9.781611 ,\n",
       "          -9.743822 ,  -9.857191 ],\n",
       "        [-10.172107 , -10.00835  , -10.00835  , ...,  -9.869788 ,\n",
       "          -9.831998 ,  -9.932771 ],\n",
       "        [-10.1973   , -10.12172  , -10.12172  , ...,  -9.957964 ,\n",
       "          -9.945368 ,  -9.995754 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-10.27288  , -10.222493 ,  -9.9075775, ..., -10.335862 ,\n",
       "         -10.373652 , -10.550005 ],\n",
       "        [-10.335862 , -10.247686 ,  -9.869788 , ..., -10.298073 ,\n",
       "         -10.348459 , -10.537409 ],\n",
       "        [-10.109123 , -10.146914 ,  -9.857191 , ..., -10.033544 ,\n",
       "         -10.146914 , -10.361055 ],\n",
       "        ...,\n",
       "        [ -9.932771 ,  -9.529679 ,  -9.403713 , ...,  -9.857191 ,\n",
       "          -9.857191 ,  -9.706032 ],\n",
       "        [-10.222493 ,  -9.819402 ,  -9.655645 , ...,  -9.643049 ,\n",
       "          -9.731225 ,  -9.718629 ],\n",
       "        [ -9.794209 ,  -9.743822 ,  -9.706032 , ...,  -9.391117 ,\n",
       "          -9.49189  ,  -9.580066 ]],\n",
       "\n",
       "       [[ -9.932771 , -10.235089 , -10.323266 , ..., -10.600391 ,\n",
       "         -10.386249 , -10.298073 ],\n",
       "        [-10.046141 , -10.361055 , -10.411442 , ..., -10.6129875,\n",
       "         -10.323266 , -10.335862 ],\n",
       "        [-10.235089 , -10.461828 , -10.373652 , ..., -10.864921 ,\n",
       "         -10.6129875, -10.562601 ],\n",
       "        ...,\n",
       "        [-10.096527 , -10.209896 , -10.172107 , ...,  -9.680839 ,\n",
       "          -9.857191 ,  -9.743822 ],\n",
       "        [-10.487021 , -10.587795 , -10.373652 , ...,  -9.769015 ,\n",
       "          -9.920175 ,  -9.542276 ],\n",
       "        [-10.146914 , -10.638182 , -10.512215 , ..., -10.361055 ,\n",
       "         -10.436635 , -10.12172  ]],\n",
       "\n",
       "       [[-10.82713  , -11.129449 , -11.154642 , ..., -10.033544 ,\n",
       "          -9.995754 ,  -9.932771 ],\n",
       "        [ -9.592663 , -10.00835  , -10.499619 , ...,  -9.869788 ,\n",
       "          -9.957964 ,  -9.882384 ],\n",
       "        [-10.461828 , -10.348459 , -10.096527 , ...,  -9.957964 ,\n",
       "         -10.109123 , -10.00835  ],\n",
       "        ...,\n",
       "        [ -8.106262 ,  -8.307808 ,  -8.899849 , ...,  -8.925042 ,\n",
       "          -9.051008 ,  -9.5548725],\n",
       "        [ -8.282615 ,  -8.219632 ,  -8.723496 , ...,  -8.799076 ,\n",
       "          -8.912446 ,  -9.479293 ],\n",
       "        [ -9.592663 ,  -8.950235 ,  -8.761286 , ...,  -8.811672 ,\n",
       "          -9.101395 ,  -9.328134 ]]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "batch_size = 100\n",
    "X_train, y_train = torch.tensor(X_train).to(device), torch.tensor(y_train).to(device)\n",
    "X_test, y_test = torch.tensor(X_test).to(device), torch.tensor(y_test).to(device)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "dataset_sizes = {'train': len(train_dataset), 'val': len(test_dataset)}\n",
    "dataloaders = {'train': train_loader, 'val': test_loader}\n",
    "class_names = list(label_map.keys())\n",
    "print(class_names)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['imagine_both_feet', 'imagine_both_fist', 'imagine_left_fist', 'imagine_right_fist']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs-1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0.0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            writer.add_scalar(f'{phase} loss', epoch_loss, epoch)\n",
    "            writer.add_scalar(f'{phase} accuracy', epoch_acc, epoch)\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed%60:.0f}s')\n",
    "    print(f'Best val acc: {best_acc:.4f}')\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "input_size = 64\n",
    "sequence_length = seq_len\n",
    "hidden_size = 512\n",
    "num_layers = 2\n",
    "num_classes = 4\n",
    "num_epochs = 100\n",
    "batch_size = 100\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        # x-> batch_size, seq, input_size\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "\n",
    "        out, _ = self.rnn(x, (h0, c0))\n",
    "        # out: batch_size, seq_length, hidden_size\n",
    "        # out: (N, 28, 128)\n",
    "        out = out[:, -1, :]\n",
    "        # out (N, 128)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "writer.add_graph(model, X_train)\n",
    "\n",
    "model = train_model(model, criterion, optimizer, num_epochs=num_epochs)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0/99\n",
      "----------\n",
      "train Loss: 1.3921 Acc: 0.2653\n",
      "val Loss: 1.3889 Acc: 0.2458\n",
      "\n",
      "Epoch 1/99\n",
      "----------\n",
      "train Loss: 1.3795 Acc: 0.2758\n",
      "val Loss: 1.3956 Acc: 0.2576\n",
      "\n",
      "Epoch 2/99\n",
      "----------\n",
      "train Loss: 1.3708 Acc: 0.3008\n",
      "val Loss: 1.3782 Acc: 0.2525\n",
      "\n",
      "Epoch 3/99\n",
      "----------\n",
      "train Loss: 1.3601 Acc: 0.3051\n",
      "val Loss: 1.3976 Acc: 0.2593\n",
      "\n",
      "Epoch 4/99\n",
      "----------\n",
      "train Loss: 1.3515 Acc: 0.3237\n",
      "val Loss: 1.3832 Acc: 0.2644\n",
      "\n",
      "Epoch 5/99\n",
      "----------\n",
      "train Loss: 1.3423 Acc: 0.3220\n",
      "val Loss: 1.3717 Acc: 0.2983\n",
      "\n",
      "Epoch 6/99\n",
      "----------\n",
      "train Loss: 1.3245 Acc: 0.3504\n",
      "val Loss: 1.3865 Acc: 0.2847\n",
      "\n",
      "Epoch 7/99\n",
      "----------\n",
      "train Loss: 1.3113 Acc: 0.3564\n",
      "val Loss: 1.4019 Acc: 0.2695\n",
      "\n",
      "Epoch 8/99\n",
      "----------\n",
      "train Loss: 1.2818 Acc: 0.3669\n",
      "val Loss: 1.4488 Acc: 0.2559\n",
      "\n",
      "Epoch 9/99\n",
      "----------\n",
      "train Loss: 1.2661 Acc: 0.3758\n",
      "val Loss: 1.3823 Acc: 0.3068\n",
      "\n",
      "Epoch 10/99\n",
      "----------\n",
      "train Loss: 1.2525 Acc: 0.3949\n",
      "val Loss: 1.3884 Acc: 0.3203\n",
      "\n",
      "Epoch 11/99\n",
      "----------\n",
      "train Loss: 1.2315 Acc: 0.4144\n",
      "val Loss: 1.4123 Acc: 0.2864\n",
      "\n",
      "Epoch 12/99\n",
      "----------\n",
      "train Loss: 1.2227 Acc: 0.4233\n",
      "val Loss: 1.3988 Acc: 0.3034\n",
      "\n",
      "Epoch 13/99\n",
      "----------\n",
      "train Loss: 1.1984 Acc: 0.4318\n",
      "val Loss: 1.4920 Acc: 0.2898\n",
      "\n",
      "Epoch 14/99\n",
      "----------\n",
      "train Loss: 1.1738 Acc: 0.4508\n",
      "val Loss: 1.4971 Acc: 0.3203\n",
      "\n",
      "Epoch 15/99\n",
      "----------\n",
      "train Loss: 1.1549 Acc: 0.4593\n",
      "val Loss: 1.4579 Acc: 0.3017\n",
      "\n",
      "Epoch 16/99\n",
      "----------\n",
      "train Loss: 1.1368 Acc: 0.4856\n",
      "val Loss: 1.4411 Acc: 0.3373\n",
      "\n",
      "Epoch 17/99\n",
      "----------\n",
      "train Loss: 1.1041 Acc: 0.4941\n",
      "val Loss: 1.5193 Acc: 0.2949\n",
      "\n",
      "Epoch 18/99\n",
      "----------\n",
      "train Loss: 1.0722 Acc: 0.5199\n",
      "val Loss: 1.5039 Acc: 0.3339\n",
      "\n",
      "Epoch 19/99\n",
      "----------\n",
      "train Loss: 1.0361 Acc: 0.5258\n",
      "val Loss: 1.5961 Acc: 0.3237\n",
      "\n",
      "Epoch 20/99\n",
      "----------\n",
      "train Loss: 0.9695 Acc: 0.5665\n",
      "val Loss: 1.7318 Acc: 0.3203\n",
      "\n",
      "Epoch 21/99\n",
      "----------\n",
      "train Loss: 0.9407 Acc: 0.5877\n",
      "val Loss: 1.6891 Acc: 0.3085\n",
      "\n",
      "Epoch 22/99\n",
      "----------\n",
      "train Loss: 0.8972 Acc: 0.5992\n",
      "val Loss: 1.7359 Acc: 0.3254\n",
      "\n",
      "Epoch 23/99\n",
      "----------\n",
      "train Loss: 0.8830 Acc: 0.6059\n",
      "val Loss: 1.8177 Acc: 0.3186\n",
      "\n",
      "Epoch 24/99\n",
      "----------\n",
      "train Loss: 0.8313 Acc: 0.6347\n",
      "val Loss: 1.9196 Acc: 0.3322\n",
      "\n",
      "Epoch 25/99\n",
      "----------\n",
      "train Loss: 1.0196 Acc: 0.5843\n",
      "val Loss: 1.5535 Acc: 0.2949\n",
      "\n",
      "Epoch 26/99\n",
      "----------\n",
      "train Loss: 0.9908 Acc: 0.5644\n",
      "val Loss: 1.6919 Acc: 0.2966\n",
      "\n",
      "Epoch 27/99\n",
      "----------\n",
      "train Loss: 0.8171 Acc: 0.6432\n",
      "val Loss: 1.9124 Acc: 0.3237\n",
      "\n",
      "Epoch 28/99\n",
      "----------\n",
      "train Loss: 0.7175 Acc: 0.6877\n",
      "val Loss: 2.1533 Acc: 0.3102\n",
      "\n",
      "Epoch 29/99\n",
      "----------\n",
      "train Loss: 0.6946 Acc: 0.6996\n",
      "val Loss: 2.0976 Acc: 0.3136\n",
      "\n",
      "Epoch 30/99\n",
      "----------\n",
      "train Loss: 0.6384 Acc: 0.7331\n",
      "val Loss: 2.3098 Acc: 0.3017\n",
      "\n",
      "Epoch 31/99\n",
      "----------\n",
      "train Loss: 0.5732 Acc: 0.7699\n",
      "val Loss: 2.3999 Acc: 0.3271\n",
      "\n",
      "Epoch 32/99\n",
      "----------\n",
      "train Loss: 0.5713 Acc: 0.7589\n",
      "val Loss: 2.4246 Acc: 0.3203\n",
      "\n",
      "Epoch 33/99\n",
      "----------\n",
      "train Loss: 0.4910 Acc: 0.8051\n",
      "val Loss: 2.6992 Acc: 0.3169\n",
      "\n",
      "Epoch 34/99\n",
      "----------\n",
      "train Loss: 0.4256 Acc: 0.8305\n",
      "val Loss: 2.7938 Acc: 0.2949\n",
      "\n",
      "Epoch 35/99\n",
      "----------\n",
      "train Loss: 0.4364 Acc: 0.8288\n",
      "val Loss: 2.8636 Acc: 0.3136\n",
      "\n",
      "Epoch 36/99\n",
      "----------\n",
      "train Loss: 0.3892 Acc: 0.8487\n",
      "val Loss: 2.8297 Acc: 0.3085\n",
      "\n",
      "Epoch 37/99\n",
      "----------\n",
      "train Loss: 0.3625 Acc: 0.8589\n",
      "val Loss: 2.9809 Acc: 0.3000\n",
      "\n",
      "Epoch 38/99\n",
      "----------\n",
      "train Loss: 0.3145 Acc: 0.8869\n",
      "val Loss: 3.1850 Acc: 0.3153\n",
      "\n",
      "Epoch 39/99\n",
      "----------\n",
      "train Loss: 0.2543 Acc: 0.9042\n",
      "val Loss: 3.1042 Acc: 0.3322\n",
      "\n",
      "Epoch 40/99\n",
      "----------\n",
      "train Loss: 0.2257 Acc: 0.9148\n",
      "val Loss: 3.3400 Acc: 0.3220\n",
      "\n",
      "Epoch 41/99\n",
      "----------\n",
      "train Loss: 0.2223 Acc: 0.9203\n",
      "val Loss: 3.2843 Acc: 0.3441\n",
      "\n",
      "Epoch 42/99\n",
      "----------\n",
      "train Loss: 0.2069 Acc: 0.9208\n",
      "val Loss: 3.3906 Acc: 0.2898\n",
      "\n",
      "Epoch 43/99\n",
      "----------\n",
      "train Loss: 0.1791 Acc: 0.9424\n",
      "val Loss: 3.3979 Acc: 0.3220\n",
      "\n",
      "Epoch 44/99\n",
      "----------\n",
      "train Loss: 0.1153 Acc: 0.9640\n",
      "val Loss: 3.7954 Acc: 0.3237\n",
      "\n",
      "Epoch 45/99\n",
      "----------\n",
      "train Loss: 0.1463 Acc: 0.9547\n",
      "val Loss: 3.6796 Acc: 0.3102\n",
      "\n",
      "Epoch 46/99\n",
      "----------\n",
      "train Loss: 0.1241 Acc: 0.9542\n",
      "val Loss: 3.6496 Acc: 0.3271\n",
      "\n",
      "Epoch 47/99\n",
      "----------\n",
      "train Loss: 0.1569 Acc: 0.9479\n",
      "val Loss: 3.8335 Acc: 0.2915\n",
      "\n",
      "Epoch 48/99\n",
      "----------\n",
      "train Loss: 0.1378 Acc: 0.9576\n",
      "val Loss: 3.8562 Acc: 0.2881\n",
      "\n",
      "Epoch 49/99\n",
      "----------\n",
      "train Loss: 0.1142 Acc: 0.9644\n",
      "val Loss: 3.7629 Acc: 0.2966\n",
      "\n",
      "Epoch 50/99\n",
      "----------\n",
      "train Loss: 0.0678 Acc: 0.9814\n",
      "val Loss: 3.9817 Acc: 0.3119\n",
      "\n",
      "Epoch 51/99\n",
      "----------\n",
      "train Loss: 0.0411 Acc: 0.9915\n",
      "val Loss: 4.0485 Acc: 0.3051\n",
      "\n",
      "Epoch 52/99\n",
      "----------\n",
      "train Loss: 0.0227 Acc: 0.9953\n",
      "val Loss: 4.3579 Acc: 0.3136\n",
      "\n",
      "Epoch 53/99\n",
      "----------\n",
      "train Loss: 0.0169 Acc: 0.9958\n",
      "val Loss: 4.5865 Acc: 0.3085\n",
      "\n",
      "Epoch 54/99\n",
      "----------\n",
      "train Loss: 0.0268 Acc: 0.9936\n",
      "val Loss: 4.2728 Acc: 0.3356\n",
      "\n",
      "Epoch 55/99\n",
      "----------\n",
      "train Loss: 0.0254 Acc: 0.9919\n",
      "val Loss: 4.3403 Acc: 0.3169\n",
      "\n",
      "Epoch 56/99\n",
      "----------\n",
      "train Loss: 0.0146 Acc: 0.9966\n",
      "val Loss: 4.4104 Acc: 0.3237\n",
      "\n",
      "Epoch 57/99\n",
      "----------\n",
      "train Loss: 0.0113 Acc: 0.9975\n",
      "val Loss: 4.4416 Acc: 0.3254\n",
      "\n",
      "Epoch 58/99\n",
      "----------\n",
      "train Loss: 0.0069 Acc: 0.9987\n",
      "val Loss: 4.5428 Acc: 0.3373\n",
      "\n",
      "Epoch 59/99\n",
      "----------\n",
      "train Loss: 0.0018 Acc: 1.0000\n",
      "val Loss: 4.5992 Acc: 0.3322\n",
      "\n",
      "Epoch 60/99\n",
      "----------\n",
      "train Loss: 0.0012 Acc: 1.0000\n",
      "val Loss: 4.6451 Acc: 0.3305\n",
      "\n",
      "Epoch 61/99\n",
      "----------\n",
      "train Loss: 0.0008 Acc: 1.0000\n",
      "val Loss: 4.7022 Acc: 0.3305\n",
      "\n",
      "Epoch 62/99\n",
      "----------\n",
      "train Loss: 0.0005 Acc: 1.0000\n",
      "val Loss: 4.7461 Acc: 0.3237\n",
      "\n",
      "Epoch 63/99\n",
      "----------\n",
      "train Loss: 0.0005 Acc: 1.0000\n",
      "val Loss: 4.7759 Acc: 0.3237\n",
      "\n",
      "Epoch 64/99\n",
      "----------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "val Loss: 4.8041 Acc: 0.3271\n",
      "\n",
      "Epoch 65/99\n",
      "----------\n",
      "train Loss: 0.0004 Acc: 1.0000\n",
      "val Loss: 4.8297 Acc: 0.3237\n",
      "\n",
      "Epoch 66/99\n",
      "----------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "val Loss: 4.8529 Acc: 0.3237\n",
      "\n",
      "Epoch 67/99\n",
      "----------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "val Loss: 4.8756 Acc: 0.3237\n",
      "\n",
      "Epoch 68/99\n",
      "----------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "val Loss: 4.8974 Acc: 0.3237\n",
      "\n",
      "Epoch 69/99\n",
      "----------\n",
      "train Loss: 0.0003 Acc: 1.0000\n",
      "val Loss: 4.9184 Acc: 0.3237\n",
      "\n",
      "Epoch 70/99\n",
      "----------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "val Loss: 4.9365 Acc: 0.3254\n",
      "\n",
      "Epoch 71/99\n",
      "----------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "val Loss: 4.9558 Acc: 0.3254\n",
      "\n",
      "Epoch 72/99\n",
      "----------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "val Loss: 4.9753 Acc: 0.3254\n",
      "\n",
      "Epoch 73/99\n",
      "----------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "val Loss: 4.9922 Acc: 0.3254\n",
      "\n",
      "Epoch 74/99\n",
      "----------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "val Loss: 5.0090 Acc: 0.3254\n",
      "\n",
      "Epoch 75/99\n",
      "----------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "val Loss: 5.0252 Acc: 0.3254\n",
      "\n",
      "Epoch 76/99\n",
      "----------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "val Loss: 5.0402 Acc: 0.3254\n",
      "\n",
      "Epoch 77/99\n",
      "----------\n",
      "train Loss: 0.0002 Acc: 1.0000\n",
      "val Loss: 5.0554 Acc: 0.3271\n",
      "\n",
      "Epoch 78/99\n",
      "----------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 5.0699 Acc: 0.3254\n",
      "\n",
      "Epoch 79/99\n",
      "----------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 5.0836 Acc: 0.3254\n",
      "\n",
      "Epoch 80/99\n",
      "----------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 5.0966 Acc: 0.3254\n",
      "\n",
      "Epoch 81/99\n",
      "----------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 5.1093 Acc: 0.3254\n",
      "\n",
      "Epoch 82/99\n",
      "----------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 5.1220 Acc: 0.3254\n",
      "\n",
      "Epoch 83/99\n",
      "----------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 5.1346 Acc: 0.3254\n",
      "\n",
      "Epoch 84/99\n",
      "----------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 5.1460 Acc: 0.3254\n",
      "\n",
      "Epoch 85/99\n",
      "----------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 5.1579 Acc: 0.3254\n",
      "\n",
      "Epoch 86/99\n",
      "----------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 5.1698 Acc: 0.3254\n",
      "\n",
      "Epoch 87/99\n",
      "----------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 5.1809 Acc: 0.3254\n",
      "\n",
      "Epoch 88/99\n",
      "----------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 5.1923 Acc: 0.3254\n",
      "\n",
      "Epoch 89/99\n",
      "----------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 5.2035 Acc: 0.3254\n",
      "\n",
      "Epoch 90/99\n",
      "----------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 5.2141 Acc: 0.3254\n",
      "\n",
      "Epoch 91/99\n",
      "----------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 5.2244 Acc: 0.3254\n",
      "\n",
      "Epoch 92/99\n",
      "----------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 5.2350 Acc: 0.3254\n",
      "\n",
      "Epoch 93/99\n",
      "----------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 5.2448 Acc: 0.3271\n",
      "\n",
      "Epoch 94/99\n",
      "----------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 5.2548 Acc: 0.3271\n",
      "\n",
      "Epoch 95/99\n",
      "----------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 5.2649 Acc: 0.3271\n",
      "\n",
      "Epoch 96/99\n",
      "----------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 5.2744 Acc: 0.3271\n",
      "\n",
      "Epoch 97/99\n",
      "----------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 5.2845 Acc: 0.3271\n",
      "\n",
      "Epoch 98/99\n",
      "----------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 5.2937 Acc: 0.3271\n",
      "\n",
      "Epoch 99/99\n",
      "----------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 5.3028 Acc: 0.3271\n",
      "\n",
      "Training complete in 4m 54s\n",
      "Best val acc: 0.3441\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "_, y_pred = torch.max(model(X_test), 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "cr = classification_report(y_test.cpu().numpy(), y_pred.cpu().numpy())\n",
    "print(cr)\n",
    "\n",
    "cm = confusion_matrix(y_test.cpu().numpy(), y_pred.cpu().numpy())\n",
    "print(cm)\n",
    "\n",
    "y_pred_ohe = np.zeros((y_pred.size(0), num_classes))\n",
    "for i, j in enumerate(y_pred):\n",
    "    y_pred_ohe[i, j] = 1\n",
    "\n",
    "y_test_ohe = np.zeros((y_test.size(0), num_classes))\n",
    "for i, j in enumerate(y_test):\n",
    "    y_test_ohe[i, j] = 1\n",
    "auroc = roc_auc_score(y_test_ohe, y_pred_ohe, multi_class='ovo')\n",
    "writer.add_scalar('AUROC OvO', auroc)\n",
    "print('AUROC ovo:', auroc)\n",
    "auroc = roc_auc_score(y_test_ohe, y_pred_ohe, multi_class='ovr')\n",
    "writer.add_scalar('AUROC OvR', auroc)\n",
    "print('AUROC ovr:', auroc)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.28      0.30       146\n",
      "           1       0.37      0.42      0.39       149\n",
      "           2       0.35      0.35      0.35       153\n",
      "           3       0.32      0.32      0.32       142\n",
      "\n",
      "    accuracy                           0.34       590\n",
      "   macro avg       0.34      0.34      0.34       590\n",
      "weighted avg       0.34      0.34      0.34       590\n",
      "\n",
      "[[41 44 31 30]\n",
      " [22 62 38 27]\n",
      " [29 31 54 39]\n",
      " [35 30 31 46]]\n",
      "AUROC ovo: 0.562363317597656\n",
      "AUROC ovr: 0.562363317597656\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "{str(v): k for k, v in label_map.items()}"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'0': 'imagine_both_feet',\n",
       " '1': 'imagine_both_fist',\n",
       " '2': 'imagine_left_fist',\n",
       " '3': 'imagine_right_fist'}"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "figure = plt.figure(figsize=(7, 5))\n",
    "cm_df = pd.DataFrame(cm, columns=class_names, index=class_names)\n",
    "sns.heatmap(cm_df, annot=True, fmt='g')\n",
    "plt.ylabel('True')\n",
    "plt.xlabel('Pred')\n",
    "plt.tight_layout()\n",
    "plt.savefig('runs/fcn/cm.png')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 504x360 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Number of trainable parameters')\n",
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of trainable parameters\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3287044"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('env': venv)"
  },
  "interpreter": {
   "hash": "6a647b8c8fb6b9194b82e32092c9482e7e42dcb66eef6eb2ec21ed1080262273"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
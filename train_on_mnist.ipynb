{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sqeeze(object):\n",
    "    def __call__(self, sample):\n",
    "        sqzd = torch.squeeze(sample)\n",
    "        return sqzd\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return 'Squeze()'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.1307,), (0.3081)),\n",
    "    Sqeeze()\n",
    "])\n",
    "\n",
    "mnist_train = torchvision.datasets.MNIST(root='./dataset', train=True, download=True, transform=transform)\n",
    "mnist_test = torchvision.datasets.MNIST(root='./dataset', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_data = mnist_train.data\n",
    "mnist_train_labels = mnist_train.targets\n",
    "mnist_test_data = mnist_test.data\n",
    "mnist_test_labels = mnist_test.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_data_0 = mnist_train_data[mnist_train_labels == 0]\n",
    "mnist_train_data_1 = mnist_train_data[mnist_train_labels == 1]\n",
    "mnist_train_data_2 = mnist_train_data[mnist_train_labels == 2]\n",
    "\n",
    "mnist_test_data_0 = mnist_test_data[mnist_test_labels == 0]\n",
    "mnist_test_data_1 = mnist_test_data[mnist_test_labels == 1]\n",
    "mnist_test_data_2 = mnist_test_data[mnist_test_labels == 2]\n",
    "\n",
    "mnist_train_labels_0 = mnist_train_labels[mnist_train_labels == 0]\n",
    "mnist_train_labels_1 = mnist_train_labels[mnist_train_labels == 1]\n",
    "mnist_train_labels_2 = mnist_train_labels[mnist_train_labels == 2]\n",
    "\n",
    "mnist_test_labels_0 = mnist_test_labels[mnist_test_labels == 0]\n",
    "mnist_test_labels_1 = mnist_test_labels[mnist_test_labels == 1]\n",
    "mnist_test_labels_2 = mnist_test_labels[mnist_test_labels == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_data = np.vstack([mnist_train_data_0, mnist_train_data_1, mnist_train_data_2])\n",
    "mnist_train_labels = np.hstack([mnist_train_labels_0, mnist_train_labels_1, mnist_train_labels_2])\n",
    "# mnist_train_labels = (mnist_train_labels == 8) + 0\n",
    "\n",
    "mnist_test_data = np.vstack([mnist_test_data_0, mnist_test_data_1, mnist_test_data_2])\n",
    "mnist_test_labels = np.hstack([mnist_test_labels_0, mnist_test_labels_1, mnist_test_labels_2])\n",
    "# mnist_test_labels = (mnist_test_labels == 8) + 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "mnist_train_data, mnist_train_labels = torch.tensor(mnist_train_data).to(device), torch.tensor(mnist_train_labels).to(device)\n",
    "mnist_test_data, mnist_test_labels = torch.tensor(mnist_test_data).to(device), torch.tensor(mnist_test_labels).to(device)\n",
    "\n",
    "mnist_train_data = torchvision.transforms.Normalize((0.1307,), (0.3081))(mnist_train_data.float())\n",
    "mnist_test_data = torchvision.transforms.Normalize((0.1307,), (0.3081))(mnist_test_data.float())\n",
    "\n",
    "mnist_train = TensorDataset(mnist_train_data, mnist_train_labels)\n",
    "mnist_test = TensorDataset(mnist_test_data, mnist_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(mnist_train, batch_size=32, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(mnist_test, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 28, 28])\n",
      "torch.float32\n",
      "torch.Size([32])\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "for input, label in test_dataloader:\n",
    "    print(input.shape)\n",
    "    print(input.dtype)\n",
    "    print(label.shape)\n",
    "    print(label.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from main import run_model, init_model_params\n",
    "from datetime import datetime\n",
    "from models import GCNAuto\n",
    "\n",
    "model_name = 'imagine_gcn_auto'\n",
    "random_seed = 0\n",
    "dataset_name = 'mnist'\n",
    "time_now = datetime.now().strftime('%Y-%m-%d-%H-%M')\n",
    "results_path = os.path.join('output', time_now, model_name, dataset_name, str(random_seed))\n",
    "os.makedirs(results_path, exist_ok=True)\n",
    "\n",
    "model = GCNAuto(in_features=28, n_nodes=28, num_classes=3, hidden_sizes=[256, 512, 256], dropout_p=0.2, device=device)\n",
    "\n",
    "dataset_sizes = {'train': len(train_dataloader), 'val': len(test_dataloader), 'test': len(test_dataloader)}\n",
    "dataloaders = {'train': train_dataloader, 'val': test_dataloader, 'test': test_dataloader}\n",
    "class_names = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 582, 'val': 99, 'test': 99}\n",
      "{'train': 582, 'val': 99}\n"
     ]
    }
   ],
   "source": [
    "print(dataset_sizes)\n",
    "dataset_sizes = {x: len(dataloaders[x]) for x in ['train', 'val']}\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_model_params(model, random_seed=random_seed)\n",
    "model.init_node_embeddings()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train() called: model=GCNAuto, opt=Adam(lr=0.001000), epochs=2, device=cuda\n",
      "\n",
      "Epoch   1/  2, train loss:  6.55, train acc:  0.97, val loss:  0.81, val acc:  0.98\n",
      "\n",
      "Time total:      4.48 sec\n",
      "Time per epoch:  2.24 sec\n",
      "[0 1 2]\n",
      "output/2022-01-07-11-47/imagine_gcn_auto/mnist/0\n"
     ]
    }
   ],
   "source": [
    "run_model(random_seed, dataloaders, dataset_sizes, class_names, model, results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3147, 28, 28])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(mnist_test_data)\n",
    "    _, y_preds = torch.max(outputs, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report(mnist_test_labels.cpu().numpy(), y_preds.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       980\n",
      "           1       1.00      0.99      0.99      1135\n",
      "           2       0.98      0.99      0.99      1032\n",
      "\n",
      "    accuracy                           0.99      3147\n",
      "   macro avg       0.99      0.99      0.99      3147\n",
      "weighted avg       0.99      0.99      0.99      3147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New training func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(model, optimizer, loss_fn, train_dl, val_dl, epochs=100, device='cpu'):\n",
    "\n",
    "    print('train() called: model=%s, opt=%s(lr=%f), epochs=%d, device=%s\\n' % \\\n",
    "          (type(model).__name__, type(optimizer).__name__,\n",
    "           optimizer.param_groups[0]['lr'], epochs, device))\n",
    "\n",
    "    history = {} # Collects per-epoch loss and acc like Keras' fit().\n",
    "    history['loss'] = []\n",
    "    history['val_loss'] = []\n",
    "    history['acc'] = []\n",
    "    history['val_acc'] = []\n",
    "\n",
    "    start_time_sec = time.time()\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "\n",
    "        # --- TRAIN AND EVALUATE ON TRAINING SET -----------------------------\n",
    "        model.train()\n",
    "        train_loss         = 0.0\n",
    "        num_train_correct  = 0\n",
    "        num_train_examples = 0\n",
    "\n",
    "        for batch in train_dl:\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x    = batch[0].to(device)\n",
    "            y    = batch[1].to(device)\n",
    "            yhat = model(x)\n",
    "            loss = loss_fn(yhat, y)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss         += loss.data.item() * x.size(0)\n",
    "            num_train_correct  += (torch.max(yhat, 1)[1] == y).sum().item()\n",
    "            num_train_examples += x.shape[0]\n",
    "\n",
    "        train_acc   = num_train_correct / num_train_examples\n",
    "        train_loss  = train_loss / len(train_dl.dataset)\n",
    "\n",
    "\n",
    "        # --- EVALUATE ON VALIDATION SET -------------------------------------\n",
    "        model.eval()\n",
    "        val_loss       = 0.0\n",
    "        num_val_correct  = 0\n",
    "        num_val_examples = 0\n",
    "\n",
    "        for batch in val_dl:\n",
    "\n",
    "            x    = batch[0].to(device)\n",
    "            y    = batch[1].to(device)\n",
    "            yhat = model(x)\n",
    "            loss = loss_fn(yhat, y)\n",
    "\n",
    "            val_loss         += loss.data.item() * x.size(0)\n",
    "            num_val_correct  += (torch.max(yhat, 1)[1] == y).sum().item()\n",
    "            num_val_examples += y.shape[0]\n",
    "\n",
    "        val_acc  = num_val_correct / num_val_examples\n",
    "        val_loss = val_loss / len(val_dl.dataset)\n",
    "\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "          print('Epoch %3d/%3d, train loss: %5.2f, train acc: %5.2f, val loss: %5.2f, val acc: %5.2f' % \\\n",
    "                (epoch, epochs, train_loss, train_acc, val_loss, val_acc))\n",
    "\n",
    "        history['loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "\n",
    "    # END OF TRAINING LOOP\n",
    "\n",
    "\n",
    "    end_time_sec       = time.time()\n",
    "    total_time_sec     = end_time_sec - start_time_sec\n",
    "    time_per_epoch_sec = total_time_sec / epochs\n",
    "    print()\n",
    "    print('Time total:     %5.2f sec' % (total_time_sec))\n",
    "    print('Time per epoch: %5.2f sec' % (time_per_epoch_sec))\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train() called: model=GCNAuto, opt=Adam(lr=0.001000), epochs=100, device=cuda\n",
      "\n",
      "Epoch   1/100, train loss:  1.18, train acc:  0.98, val loss:  0.39, val acc:  0.99\n",
      "Epoch  10/100, train loss:  0.05, train acc:  0.99, val loss:  0.15, val acc:  0.99\n",
      "Epoch  20/100, train loss:  0.07, train acc:  0.99, val loss:  0.03, val acc:  0.99\n",
      "Epoch  30/100, train loss:  0.05, train acc:  0.99, val loss:  0.10, val acc:  0.99\n",
      "Epoch  40/100, train loss:  0.10, train acc:  0.98, val loss:  0.04, val acc:  0.99\n",
      "Epoch  50/100, train loss:  0.05, train acc:  0.99, val loss:  0.09, val acc:  0.98\n",
      "Epoch  60/100, train loss:  0.12, train acc:  0.97, val loss:  0.12, val acc:  0.97\n",
      "Epoch  70/100, train loss:  0.10, train acc:  0.98, val loss:  0.11, val acc:  0.99\n",
      "Epoch  80/100, train loss:  0.28, train acc:  0.94, val loss:  0.20, val acc:  0.98\n",
      "Epoch  90/100, train loss:  0.14, train acc:  0.97, val loss:  0.11, val acc:  0.99\n",
      "Epoch 100/100, train loss:  0.30, train acc:  0.91, val loss:  0.56, val acc:  0.98\n",
      "\n",
      "Time total:     195.58 sec\n",
      "Time per epoch:  1.96 sec\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, PARAMS['SCHEDULER_STEPSIZE'], PARAMS['SCHEDULER_GAMMA'])\n",
    "\n",
    "history = train(\n",
    "    model = model,\n",
    "    optimizer = optimizer,\n",
    "    loss_fn = criterion,\n",
    "    train_dl = train_dataloader,\n",
    "    val_dl = test_dataloader,\n",
    "    device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "84c85347d78e9e1e10700c6d8e0f5eee9b662a9651d925575cf1524e055e4541"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, Dataset\n",
    "\n",
    "import numpy as np \n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "random_seed = 1\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('runs/gnn')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load data and normalize"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "X = pickle.load(open('../dataset/train/cross_subject_data_5_subjects.pickle', 'rb'))\n",
    "y = X['train_y']\n",
    "\n",
    "X = X['train_x'].astype(np.float32)\n",
    "\n",
    "label_map = {'imagine_both_feet': 0, 'imagine_both_fist': 1, 'imagine_left_fist': 2, 'imagine_right_fist': 3}\n",
    "y = np.vectorize(label_map.__getitem__)(y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Normalize\n",
    "mean, std = X.mean(), X.std()\n",
    "X = (X - mean) / std"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import Adj Matrix"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from convert_to_graphs import n_graph, d_graph, s_graph, normalize_adj\n",
    "\n",
    "seq_len = 32\n",
    "n_channels = 64\n",
    "batch_size = 32\n",
    "\n",
    "A = n_graph()\n",
    "A = np.array(A, dtype=np.float32)\n",
    "A = normalize_adj(A)\n",
    "A = A + np.eye(A.shape[0], dtype=np.float32)\n",
    "\n",
    "\n",
    "A_big = np.zeros((A.shape[0]*seq_len, A.shape[0]*seq_len), dtype=np.float32)\n",
    "print(A_big.shape)\n",
    "for i in range(0, A_big.shape[0], n_channels):\n",
    "    A_big[i:i+n_channels, i:i+n_channels] = A\n",
    "\n",
    "A_bigger = []\n",
    "for i in range(batch_size):\n",
    "    A_bigger.append(A_big)\n",
    "\n",
    "A_bigger = np.array(A_bigger, dtype=np.float32)\n",
    "\n",
    "A = torch.Tensor(A_bigger).to(device)\n",
    "\n",
    "print('Adjacency Matrix A:')\n",
    "print(A.shape)\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2048, 2048)\n",
      "Adjacency Matrix A:\n",
      "torch.Size([32, 2048, 2048])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import mne \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "ten_twenty_montage = mne.channels.make_standard_montage(\"standard_1020\")\n",
    "ch_names = pd.read_csv(\"../dataset/physionet.org_csv/S001/S001R01.csv\")\n",
    "ch_names = ch_names.columns[2:]\n",
    "\n",
    "ch_pos_1020 = ten_twenty_montage.get_positions()[\"ch_pos\"]\n",
    "\n",
    "ch_pos_1010 = {}\n",
    "for ch_name_orig in ch_names:\n",
    "    ch_name = ch_name_orig.upper().rstrip(\".\")\n",
    "    if \"Z\" in ch_name:\n",
    "        ch_name = ch_name.replace(\"Z\", \"z\")\n",
    "    if \"P\" in ch_name and len(ch_name) > 2:\n",
    "        ch_name = ch_name.replace(\"P\", \"p\")\n",
    "    if \"Cp\" in ch_name:\n",
    "        ch_name = ch_name.replace(\"Cp\", \"CP\")\n",
    "    if \"Tp\" in ch_name:\n",
    "        ch_name = ch_name.replace(\"Tp\", \"TP\")\n",
    "    if \"pO\" in ch_name:\n",
    "        ch_name = ch_name.replace(\"pO\", \"PO\")\n",
    "    ch_pos_1010[ch_name_orig] = ch_pos_1020[ch_name]\n",
    "print(len(ch_pos_1010))\n",
    "\n",
    "ch_pos_1010_names = []\n",
    "ch_pos_1010_dist = []\n",
    "for name, value in ch_pos_1010.items():\n",
    "    ch_pos_1010_names.append(name)\n",
    "    ch_pos_1010_dist.append(value)\n",
    "ch_pos_1010_dist = np.array(ch_pos_1010_dist)\n",
    "\n",
    "A = d_graph(64, ch_pos_1010_dist)\n",
    "A = np.array(A, dtype=np.float32)\n",
    "\n",
    "A = normalize_adj(A)\n",
    "A = A + np.eye(A.shape[0], dtype=np.float32)\n",
    "\n",
    "\n",
    "A_big = np.zeros((A.shape[0]*seq_len, A.shape[0]*seq_len), dtype=np.float32)\n",
    "print(A_big.shape)\n",
    "for i in range(0, A_big.shape[0], n_channels):\n",
    "    A_big[i:i+n_channels, i:i+n_channels] = A\n",
    "\n",
    "A_bigger = []\n",
    "for i in range(batch_size):\n",
    "    A_bigger.append(A_big)\n",
    "\n",
    "A_bigger = np.array(A_bigger, dtype=np.float32)\n",
    "\n",
    "A = torch.Tensor(A_bigger).to(device)\n",
    "\n",
    "print('Adjacency Matrix A:')\n",
    "print(A.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "64\n",
      "(2048, 2048)\n",
      "Adjacency Matrix A:\n",
      "torch.Size([32, 2048, 2048])\n",
      "Adjacency Matrix A:\n",
      "torch.Size([32, 2048, 2048])\n",
      "tensor([[[1.0147, 0.0682, 0.0363,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0682, 1.0147, 0.0698,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0363, 0.0698, 1.0154,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 1.0156, 0.1080, 0.1239],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.1080, 1.0158, 0.1088],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.1239, 0.1088, 1.0201]],\n",
      "\n",
      "        [[1.0147, 0.0682, 0.0363,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0682, 1.0147, 0.0698,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0363, 0.0698, 1.0154,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 1.0156, 0.1080, 0.1239],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.1080, 1.0158, 0.1088],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.1239, 0.1088, 1.0201]],\n",
      "\n",
      "        [[1.0147, 0.0682, 0.0363,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0682, 1.0147, 0.0698,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0363, 0.0698, 1.0154,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 1.0156, 0.1080, 0.1239],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.1080, 1.0158, 0.1088],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.1239, 0.1088, 1.0201]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0147, 0.0682, 0.0363,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0682, 1.0147, 0.0698,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0363, 0.0698, 1.0154,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 1.0156, 0.1080, 0.1239],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.1080, 1.0158, 0.1088],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.1239, 0.1088, 1.0201]],\n",
      "\n",
      "        [[1.0147, 0.0682, 0.0363,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0682, 1.0147, 0.0698,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0363, 0.0698, 1.0154,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 1.0156, 0.1080, 0.1239],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.1080, 1.0158, 0.1088],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.1239, 0.1088, 1.0201]],\n",
      "\n",
      "        [[1.0147, 0.0682, 0.0363,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0682, 1.0147, 0.0698,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0363, 0.0698, 1.0154,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 1.0156, 0.1080, 0.1239],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.1080, 1.0158, 0.1088],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.1239, 0.1088, 1.0201]]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/amar/Desktop/thesis-2022/env/lib/python3.7/site-packages/ipykernel_launcher.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Convert data to [n_samples, n_channels] -> [n_samples, seq_len, n_channels]"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def reshape_data_gnn(X, y, seq_len):\n",
    "    print('X original shape:', X.shape)\n",
    "    print('y original shape:', y.shape)\n",
    "    print('Seq len:', seq_len)\n",
    "    len_tail = X.shape[0] % seq_len\n",
    "    if len_tail == 0:\n",
    "        X = X.reshape(-1, seq_len*n_channels, 1)\n",
    "        y = y.reshape(-1, seq_len)\n",
    "    else:\n",
    "        X = X[:-len_tail].reshape(-1, seq_len*n_channels, 1)\n",
    "        y = y[:-len_tail].reshape(-1, seq_len)\n",
    "    y = y[:, -1]\n",
    "    print('X conversion shape:', X.shape)\n",
    "    print('y conversion shape:', y.shape)\n",
    "    return X, y\n",
    "\n",
    "X, y = reshape_data_gnn(X, y, seq_len)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X original shape: (295008, 64)\n",
      "y original shape: (295008,)\n",
      "Seq len: 32\n",
      "X conversion shape: (9219, 2048, 1)\n",
      "y conversion shape: (9219,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed, stratify=y)\n",
    "def print_class_dist(y):\n",
    "    dist = {}\n",
    "\n",
    "    labels = np.unique(y)\n",
    "    for label in labels:\n",
    "        dist[str(label)] = len(y[y == label]) / len(y)\n",
    "    print(dist)\n",
    "print_class_dist(y)\n",
    "print_class_dist(y_train)\n",
    "print_class_dist(y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'0': 0.24742379867664605, '1': 0.2530643236793578, '2': 0.2575116607007268, '3': 0.24200021694326934}\n",
      "{'0': 0.24745762711864408, '1': 0.25301694915254236, '2': 0.25749152542372883, '3': 0.24203389830508473}\n",
      "{'0': 0.2472885032537961, '1': 0.2532537960954447, '2': 0.2575921908893709, '3': 0.2418655097613883}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "X_train, y_train = torch.tensor(X_train).to(device), torch.tensor(y_train).to(device)\n",
    "X_test, y_test = torch.tensor(X_test).to(device), torch.tensor(y_test).to(device)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "dataset_sizes = {'train': len(train_dataset), 'val': len(test_dataset)}\n",
    "dataloaders = {'train': train_loader, 'val': test_loader}\n",
    "class_names = list(label_map.keys())\n",
    "print(class_names)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['imagine_both_feet', 'imagine_both_fist', 'imagine_left_fist', 'imagine_right_fist']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs-1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0.0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            writer.add_scalar(f'{phase} loss', epoch_loss, epoch)\n",
    "            writer.add_scalar(f'{phase} accuracy', epoch_acc, epoch)\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed%60:.0f}s')\n",
    "    print(f'Best val acc: {best_acc:.4f}')\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test computation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# import time\n",
    "# import torch\n",
    "# from layers_batchwise import BatchwiseGraphConvolution\n",
    "\n",
    "# torch.manual_seed(0)\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# x = torch.randn(16, 64*32, 1).to(device)\n",
    "# A = torch.randn(16, 64*32, 64*32).to(device)\n",
    "# weight = torch.randn(1, 32).to(device)\n",
    "# # A = A.to_sparse()\n",
    "# print(A.is_sparse)\n",
    "# # gcn = BatchwiseGraphConvolution(1, 32)\n",
    "# now = time.time()\n",
    "\n",
    "# support = torch.matmul(x, weight)\n",
    "# output = torch.bmm(A, support)\n",
    "\n",
    "# print('elapsed time:', time.time() - now)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "in_features = 1\n",
    "hidden_size_1 = 512\n",
    "hidden_size_2 = 512\n",
    "out_size = 4\n",
    "num_classes = 4\n",
    "num_epochs = 100\n",
    "\n",
    "from layers_batchwise import BatchwiseGraphConvolution\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_features, hidden_size_1, hidden_size_2, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.gc1 = BatchwiseGraphConvolution(in_features, hidden_size_1)\n",
    "        self.gc2 = BatchwiseGraphConvolution(hidden_size_1, hidden_size_2)\n",
    "        self.gc3 = BatchwiseGraphConvolution(hidden_size_2, out_size)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Linear(out_size*seq_len*n_channels, num_classes)\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.gc1(x, A))\n",
    "        # print(out.shape)\n",
    "        out = F.relu(self.gc2(out, A))\n",
    "        # print(out.shape)\n",
    "        out = F.relu(self.gc3(out, A))\n",
    "        # print(out.shape)\n",
    "        out = self.flatten(out)\n",
    "        # print(out.shape)\n",
    "        out = self.linear(out)\n",
    "        # print(out.shape)\n",
    "        return out\n",
    "\n",
    "model = GCN(in_features, hidden_size_1, hidden_size_2, num_classes).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# writer.add_graph(model, X_train[:10])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "model = train_model(model, criterion, optimizer, num_epochs=num_epochs)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0/99\n",
      "----------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Computation using for loop"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_preds = []\n",
    "for inputs, labels in test_loader:\n",
    "    _, y_pred = torch.max(model(inputs), 1)\n",
    "    y_preds.append(y_pred)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_preds"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "        device='cuda:0')]"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "cr = classification_report(y_test.cpu().numpy(), y_pred.cpu().numpy())\n",
    "print(cr)\n",
    "\n",
    "cm = confusion_matrix(y_test.cpu().numpy(), y_pred.cpu().numpy())\n",
    "print(cm)\n",
    "\n",
    "y_pred_ohe = np.zeros((y_pred.size(0), num_classes))\n",
    "for i, j in enumerate(y_pred):\n",
    "    y_pred_ohe[i, j] = 1\n",
    "\n",
    "y_test_ohe = np.zeros((y_test.size(0), num_classes))\n",
    "for i, j in enumerate(y_test):\n",
    "    y_test_ohe[i, j] = 1\n",
    "auroc = roc_auc_score(y_test_ohe, y_pred_ohe, multi_class='ovo')\n",
    "writer.add_scalar('AUROC OvO', auroc)\n",
    "print('AUROC ovo:', auroc)\n",
    "auroc = roc_auc_score(y_test_ohe, y_pred_ohe, multi_class='ovr')\n",
    "writer.add_scalar('AUROC OvR', auroc)\n",
    "print('AUROC ovr:', auroc)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1844, 20]",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11227/1026311941.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/thesis-2022/env/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/thesis-2022/env/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   1968\u001b[0m     \"\"\"\n\u001b[1;32m   1969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1970\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1972\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/thesis-2022/env/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/thesis-2022/env/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 320\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1844, 20]"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "{str(v): k for k, v in label_map.items()}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "figure = plt.figure(figsize=(7, 5))\n",
    "cm_df = pd.DataFrame(cm, columns=class_names, index=class_names)\n",
    "sns.heatmap(cm_df, annot=True, fmt='g')\n",
    "plt.ylabel('True')\n",
    "plt.xlabel('Pred')\n",
    "plt.tight_layout()\n",
    "plt.savefig('runs/fcn/cm.png')\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Number of trainable parameters')\n",
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of trainable parameters\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "298504"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6a647b8c8fb6b9194b82e32092c9482e7e42dcb66eef6eb2ec21ed1080262273"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('env': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}